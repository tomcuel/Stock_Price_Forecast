{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bdbac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 0. Librairies\n",
    "# ===============================\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad57eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1. Generate complex synthetic time series\n",
    "# ===============================\n",
    "def create_complex_time_series(n_samples=2000, seq_len=50, n_features=3, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    t = np.arange(n_samples + seq_len)\n",
    "    \n",
    "    series = []\n",
    "    for f in range(n_features):\n",
    "        # Different frequency sine/cosine\n",
    "        freq = np.random.uniform(0.01, 0.1)\n",
    "        amp = np.random.uniform(0.5, 2.0)\n",
    "        wave = amp * np.sin(2 * np.pi * freq * t) + amp/2 * np.cos(2 * np.pi * freq*0.5 * t)\n",
    "        \n",
    "        # Add trend\n",
    "        trend = t * np.random.uniform(0.0005, 0.002)\n",
    "        \n",
    "        # Add seasonal effect\n",
    "        season = 0.5 * np.sin(2 * np.pi * t / np.random.randint(30, 100))\n",
    "        \n",
    "        # Add noise\n",
    "        noise = np.random.normal(0, 0.2, len(t))\n",
    "        \n",
    "        # Add occasional spikes\n",
    "        spikes = np.zeros(len(t))\n",
    "        spike_idx = np.random.choice(len(t), size=int(0.01*len(t)), replace=False)\n",
    "        spikes[spike_idx] = np.random.uniform(1, 3, len(spike_idx))\n",
    "        \n",
    "        series.append(wave + trend + season + noise + spikes)\n",
    "    \n",
    "    series = np.stack(series, axis=-1)\n",
    "    \n",
    "    # Build sequences\n",
    "    X, y = [], []\n",
    "    for i in range(n_samples):\n",
    "        X.append(series[i:i+seq_len])\n",
    "        y.append(series[i+seq_len, 0])  # predict first feature as example\n",
    "    \n",
    "    X = np.array(X)  # (n_samples, seq_len, n_features)\n",
    "    y = np.array(y)  # (n_samples,)\n",
    "    return X, y, series\n",
    "\n",
    "SEQ_LEN = 50\n",
    "N_FEATURES = 3\n",
    "X, y, true_series = create_complex_time_series(n_samples=5000, seq_len=SEQ_LEN, n_features=N_FEATURES)\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ceae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 2. Plotting the time series\n",
    "# ===============================\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(true_series[:, 0], label=\"True underlying target series\")\n",
    "plt.title(\"True Continuous Time Series\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e565cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 3. Custom Attention Layers\n",
    "# ===============================\n",
    "class MultiQueryAttention(layers.Layer):\n",
    "    \"\"\"Multi-Query Attention: shared key/value projections across heads\"\"\"\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.q_dense = [layers.Dense(d_model) for _ in range(num_heads)]\n",
    "        self.k_dense = layers.Dense(d_model)  # shared\n",
    "        self.v_dense = layers.Dense(d_model)  # shared\n",
    "        self.out = layers.Dense(d_model)\n",
    "    \n",
    "    def call(self, x):\n",
    "        k = self.k_dense(x)\n",
    "        v = self.v_dense(x)\n",
    "        head_outputs = []\n",
    "        for q_layer in self.q_dense:\n",
    "            q = q_layer(x)\n",
    "            attn = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "            attn = tf.nn.softmax(attn, axis=-1)\n",
    "            head_outputs.append(tf.matmul(attn, v))\n",
    "        return self.out(tf.concat(head_outputs, axis=-1))\n",
    "\n",
    "class LatentAttention(layers.Layer):\n",
    "    \"\"\"Low-rank Latent Attention approximation\"\"\"\n",
    "    def __init__(self, d_model, latent_dim):\n",
    "        super().__init__()\n",
    "        self.q_dense = layers.Dense(latent_dim)\n",
    "        self.k_dense = layers.Dense(latent_dim)\n",
    "        self.v_dense = layers.Dense(latent_dim)\n",
    "        self.out = layers.Dense(d_model)\n",
    "    \n",
    "    def call(self, x):\n",
    "        q = self.q_dense(x)\n",
    "        k = self.k_dense(x)\n",
    "        v = self.v_dense(x)\n",
    "        attn = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(q.shape[-1], tf.float32))\n",
    "        attn = tf.nn.softmax(attn, axis=-1)\n",
    "        return self.out(tf.matmul(attn, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47057580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 4. Transformer Block\n",
    "# ===============================\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, use_mqa=False, use_latent=False, latent_dim=16):\n",
    "        super().__init__()\n",
    "        if use_latent:\n",
    "            self.attn = LatentAttention(d_model, latent_dim)\n",
    "        elif use_mqa:\n",
    "            self.attn = MultiQueryAttention(d_model, num_heads)\n",
    "        else:\n",
    "            self.attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = models.Sequential([\n",
    "            layers.Dense(ff_dim, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "        self.norm1 = layers.LayerNormalization()\n",
    "        self.norm2 = layers.LayerNormalization()\n",
    "        self.use_builtin = not isinstance(self.attn, (MultiQueryAttention, LatentAttention))\n",
    "    \n",
    "    def call(self, x):\n",
    "        if self.use_builtin:\n",
    "            attn_out = self.attn(x, x)   # standard MHA\n",
    "        else:\n",
    "            attn_out = self.attn(x)      # custom MQA/MLA\n",
    "        x = self.norm1(x + attn_out)\n",
    "        x = self.norm2(x + self.ffn(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 5. Simple Transformer Model for Time Series\n",
    "# ===============================\n",
    "class TimeSeriesTransformer(tf.keras.Model):\n",
    "    def __init__(self, seq_len, n_features, d_model=32, num_heads=2, ff_dim=64, use_mqa=False, use_latent=False, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.embedding = layers.Dense(d_model)\n",
    "        self.pos_encoding = self._positional_encoding(seq_len, d_model)\n",
    "        self.block = TransformerBlock(d_model, num_heads, ff_dim, use_mqa=use_mqa, use_latent=use_latent, latent_dim=latent_dim)\n",
    "        self.out = layers.Dense(1)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.embedding(x) + self.pos_encoding\n",
    "        x = self.block(x)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        return self.out(x)\n",
    "    \n",
    "    def _positional_encoding(self, seq_len, d_model):\n",
    "        pos = np.arange(seq_len)[:, None]\n",
    "        i = np.arange(d_model)[None, :]\n",
    "        rates = 1 / np.power(10000, (2*(i//2)) / d_model)\n",
    "        angles = pos * rates\n",
    "        pe = np.zeros_like(angles)\n",
    "        pe[:, 0::2] = np.sin(angles[:, 0::2])\n",
    "        pe[:, 1::2] = np.cos(angles[:, 1::2])\n",
    "        return tf.cast(pe[None, ...], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4496ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 6. Usage Example\n",
    "# ===============================\n",
    "transformer_model = TimeSeriesTransformer(\n",
    "    SEQ_LEN, N_FEATURES,\n",
    "    d_model=32, num_heads=2, ff_dim=64,\n",
    "    use_mqa=False,       \n",
    "    use_latent=False    \n",
    ")\n",
    "\n",
    "transformer_model.compile(optimizer='adam', loss='mse')\n",
    "transformer_history = transformer_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 7. Plot Predictions\n",
    "# ===============================\n",
    "def plot_predictions(model, X, y_true, n=200):\n",
    "    y_pred = model.predict(X[:n])\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(y_true[:n], label='True')\n",
    "    plt.plot(y_pred, label='Pred')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(transformer_model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccbcfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 8. Recursive Multi-step Forecasting\n",
    "# ===============================\n",
    "def recursive_forecast(model, X_init, n_future=100):\n",
    "    \"\"\"\n",
    "    Predict n_future steps recursively from initial sequence X_init\n",
    "    X_init: (seq_len, n_features)\n",
    "    \"\"\"\n",
    "    seq = X_init.copy()\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(n_future):\n",
    "        pred = model.predict(seq[np.newaxis, :, :])[0, 0]  # shape (1,1) -> scalar\n",
    "        predictions.append(pred)\n",
    "        \n",
    "        # Append prediction to the sequence\n",
    "        # For simplicity, keep other features unchanged or as 0\n",
    "        new_step = np.zeros(seq.shape[1])\n",
    "        new_step[0] = pred  # first feature predicted\n",
    "        seq = np.vstack([seq[1:], new_step])\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Choose the last validation sequence as starting point\n",
    "X_start = X_val[-1]\n",
    "n_future = 20\n",
    "future_transformer = recursive_forecast(transformer_model, X_start, n_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 9. Plot Future Forecasts\n",
    "# ===============================\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(np.arange(len(y_val[-200:])), y_val[-200:], label='Recent True Values', color='blue')\n",
    "plt.plot(np.arange(len(y_val[-200:]), len(y_val[-200:]) + n_future), future_transformer, label='Transformer Forecast', color='orange')\n",
    "plt.xlabel('Time step')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Multi-step Future Forecasting')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14622b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 10. Plot Predictions + Future Forecasts\n",
    "# ===============================\n",
    "def plot_predictions_and_forecast(model, X_val, y_val, n_past=200, n_future=100, label=\"Model\"):\n",
    "    \"\"\"\n",
    "    Plot past predictions on validation set and forecast n_future steps ahead.\n",
    "    \"\"\"\n",
    "    # Past predictions\n",
    "    y_pred_past = model.predict(X_val[-n_past:])\n",
    "    \n",
    "    # Future forecast starting from last sequence\n",
    "    X_start = X_val[-1]\n",
    "    future_pred = recursive_forecast(model, X_start, n_future)\n",
    "    \n",
    "    # Plot everything\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Plot past true values\n",
    "    plt.plot(np.arange(len(y_val[-n_past:])), y_val[-n_past:], label='True (Past)', color='blue')\n",
    "    # Plot past predictions\n",
    "    plt.plot(np.arange(len(y_val[-n_past:])), y_pred_past, label=f'Predicted (Past) - {label}', color='orange')\n",
    "    # Plot future forecast\n",
    "    plt.plot(np.arange(len(y_val[-n_past:]), len(y_val[-n_past:]) + n_future), future_pred, label=f'Forecast (Future) - {label}', color='green')\n",
    "    \n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'{label} - Past Predictions & Future Forecast')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot for transformers\n",
    "plot_predictions_and_forecast(transformer_model, X_val, y_val, n_past=200, n_future=100, label=\"Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 11. Plot Predictions + Long Future Forecasts\n",
    "# ===============================\n",
    "plot_predictions_and_forecast(transformer_model, X_val, y_val, n_past=1000, n_future=400, label=\"Transformer\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
